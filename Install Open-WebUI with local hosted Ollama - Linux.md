This is a setup where I have all of this installed on a local desktop (Fedora 40)

## Prereqs

- Verify the system is up to date (apt, dnf, ect)
- Verify Docker is installed
- nvidia container support (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-yum-or-dnf)

## Install Ollama

Go to the official Ollama website and run the following command as they klist in the Download secrion https://ollama.com/download

	curl -fsSL https://ollama.com/install.sh | sh


Test in the CLI to verify this installed correctly

	ollama run llama3 
** This is a test using the llama3 model, you can use other models https://ollama.com/library

If you are using a Nvidia GPU, use this to verify the GPU is being used with ollama. You should see ***ollama_llama_server*** in the nvidia-smi display when ollama is being used

	watch -n 0.5 nvidia-smi

## Install Open WebUI with openedai-speech integration (with GPU support)

These commands will generate 2 docker containers (May need to use sudo)
- Opendai-speech
- Open WebUI

#
	docker run -d --gpus=all --network=host -v tts-voices:/app/voices -v tts-config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech-min:latest
#
	docker run -d --gpus=all --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main


## Configure Open WebUI to use openedai-speech 

This info can be seen at https://docs.openwebui.com/tutorial/openedai-speech-integration

Open the Open WebUI settings and navigate to the TTS Settings under **Admin Panel > Settings > Audio**.

![openedai-tts](https://github.com/silentoplayz/docs/assets/50341825/ea08494f-2ebf-41a2-bb0f-9b48dd3ace79)

- Change TTS Settings to OpenAI (this will still use the local opendai-speech - you will see in the next step)
- **API Base URL**: `http://localhost:8000/v1`
- **API Key**: `sk-111111111` (note: this is a dummy API key, as `openedai-speech` doesn't require an API key; you can use whatever for this field)

**Choose a voice**
Under `TTS Voice` within the same audio settings menu in the admin panel, you can set the `TTS Model` to use from the following choices below that `openedai-speech` supports. The voices of these models are optimized for the English language.

- `tts-1` or `tts-1-hd`: `alloy`, `echo`, `echo-alt`, `fable`, `onyx`, `nova`, and `shimmer` (`tts-1-hd` is configurable; uses OpenAI samples by default)

## Stable Diffusion Integration
This is the Official GitHub https://github.com/AUTOMATIC1111/stable-diffusion-webui

#### Dependencies needed:

The listed commands will install webui to your current directory.

> ℹ️ Note: If you want to use a different python version installed in your system, please uncomment line 16 in `webui-user.sh` and add the existing python version:

```
python_cmd="python3.10"
# Or path:
python_cmd="/home/$USER/.pyenv/versions/3.10.6/bin/python3.10"
```

**Ubuntu 24.04**

```
sudo apt install git software-properties-common -y
sudo add-apt-repository ppa:deadsnakes/ppa -y
sudo apt install python3.10-venv -y
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui
python3.10 -m venv venv
./webui.sh
```

**Fedora 40**

```
sudo dnf install git python310 -y
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui 
python3.10 -m venv venv
./webui.sh
```

**Arch Linux**

```
sudo pacman -S git -y
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui && cd stable-diffusion-webui
```

Installation of python3.10 through **AUR** packages:

```
yay -S python310
python3.10 -m venv venv
./webui.sh
```

**Make it executable**

	chmod +x webui.sh


**Execute Program to integrate with Open-WebUI**

	./webui.sh --listen --api --api-auth user:password


**Configure Open-WebUI**
Navigate to **Admin Panel > Settings > Images** and configure these:
- Image Generation Engine: Default(Automatic1111)
- AUTOMATIC1111 Base URL: `http://localhost:7860`
- AUTOMATIC1111 Api Auth String: user:password

When these are filled out you can now turn on the image generation

![Screenshot from 2024-07-12 13-27-11.png](https://github.com/ebelious/Self-Hosted/blob/main/Images/Screenshot%20from%202024-07-12%2013-27-11.png)

** **Note**, some Models are not multi modal, thus are not able to generate images.

Some Models for Image Generation:
- llama3
- llava

Click the Icon of an image underneath the text generated by Ollama to create the image
![Screenshot from 2024-07-12 13-36-35.png](https://github.com/ebelious/Self-Hosted/blob/main/Images/Screenshot%20from%202024-07-12%2013-36-35.png)


#### Making Stable Diffusion auto start on login

Make a bash script to launch the web-ui script. Create the file with the file path to the script with the arguments and then throwing the output to /dev/null and runnign this in the background. Add the appropriate username
```
nano /home/USER/.config/autostart/stable-diffusion-start.sh
```
```
/home/USER/stable-diffusion-webui/webui.sh --listen --api --api-auth user:password > /dev/null &
```
```
chmod +x /home/USER/.config/autostart/stable-diffusion-start.sh
```

When you log in this should auto start, and you can generate images in Ollama with no issues

